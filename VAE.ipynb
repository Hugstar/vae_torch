{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 16\n",
    "class LinearVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearVAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc_fc1 = torch.nn.Linear(in_features=28*28, out_features=512)\n",
    "        self.enc_fc2 = torch.nn.Linear(in_features=512, out_features=features*2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec_fc1 = torch.nn.Linear(in_features=features*2, out_features=512)\n",
    "        self.dec_fc2 = torch.nn.Linear(in_features=512, out_features=28*28)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        Recieves log variance and mu. Outputs a sample.\n",
    "        \"\"\"\n",
    "        var = torch.exp(0.5 * log_var) # TODO: why do we have the 0.5 term?\n",
    "        eps = torch.randn_like(std) # Mean 0, Var 1\n",
    "        sample = mu + eps * var # Gives us samples with mean MU and std VAR\n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc_fc1(x))\n",
    "        x = F.relu(self.enc_fc2(x))\n",
    "        \n",
    "        # We now have some latent representation with shape [N, feature * 2]\n",
    "        # We will reshape it to shape [-1, 2, feature], so it's now [N, 2, features]\n",
    "        # Where [:, 0, :] is the mean, and [:, 1, :] is the variance\n",
    "        \n",
    "        mean = x[:, 0, :]\n",
    "        var = x[:, 1, :]\n",
    "        \n",
    "        reparameterized = self.reparameterize(mean, var)\n",
    "        \n",
    "        reconstructed = F.relu(self.dec_fc1(reparameterized))\n",
    "        reconstructed = torch.sigmoid(self.dec_fc2(reparameterized))\n",
    "        return reconstruction, mu, log_var\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leanring parameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../input/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../input/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../input/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../input/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../input/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../input/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../input/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../input/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# train and validation data\n",
    "train_data = datasets.MNIST(\n",
    "    root='../input/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "val_data = datasets.MNIST(\n",
    "    root='../input/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader (\n",
    "    train_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = DataLoader (\n",
    "    val_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.BCELoss(reduction=\"SUM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
